{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from careamics import CAREamist\n",
    "from careamics.config import create_n2v_configuration\n",
    "import numpy as np\n",
    "import logging as log\n",
    "import sys, os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Add the top-level and the script directories to the sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', 'scripts')))\n",
    "\n",
    "from helpers import get_paths, ground_truth, normalize_image\n",
    "from metrics import compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.basicConfig(level=log.INFO)\n",
    "\n",
    "def load_dataset(data_path):\n",
    "    \"\"\"\n",
    "    Load all images from the dataset into a single NumPy array.\n",
    "\n",
    "    :param data_path: Path to the root data directory.\n",
    "    :return: NumPy array of shape (120, 3, 512, 512) containing the images.\n",
    "    \"\"\"\n",
    "    log.info(f\"Loading dataset from {data_path}\")\n",
    "    \n",
    "    # Define the dataset parameters\n",
    "    num_images = 120\n",
    "    num_channels = 3\n",
    "    image_shape = (512, 512)\n",
    "    \n",
    "    # Initialize an empty array to hold the dataset\n",
    "    dataset = np.zeros((num_images, num_channels, *image_shape), dtype=np.float32)\n",
    "    \n",
    "    for channel in range(num_channels):\n",
    "        for image_index in tqdm(range(1, num_images + 1)):\n",
    "            image_index_str = str(image_index).zfill(3)\n",
    "            image_path = os.path.join(data_path, f'Image{image_index_str}', f'wf_channel{channel}.npy')\n",
    "            image = np.load(image_path)\n",
    "            dataset[image_index - 1, channel, :, :] = image[249, :, :]\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "current_working_dir = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(current_working_dir, '..'))\n",
    "\n",
    "data_path = os.path.join(parent_dir, f'data/raw')\n",
    "output_path = os.path.join(parent_dir, f'data/processed')\n",
    "log.info(f\"Data path: {data_path}\")\n",
    "log.info(f\"Output path: {output_path}\")\n",
    "\n",
    "dataset = load_dataset(data_path)\n",
    "log.info(f\"Dataset shape: {dataset.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = os.path.join(data_path, f'Image001/wf_channel0.npy')\n",
    "image = np.load(image_path)\n",
    "noisy_image = image[249, :, :]\n",
    "ground_truth_image = normalize_image(ground_truth(image))\n",
    "log.info(ground_truth_image.shape)\n",
    "log.info(noisy_image.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_bis = dataset.reshape(360, 1, 512, 512)\n",
    "\n",
    "log.info(\"Splitting the dataset into training and validation sets...\")\n",
    "split_ratio = 0.8\n",
    "split_idx = int(len(dataset_bis) * split_ratio)\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(dataset_bis)\n",
    "train, val = dataset_bis[:split_idx], dataset_bis[split_idx:]\n",
    "log.info(f\"Training set shape: {train.shape}\")\n",
    "log.info(f\"Validation set shape: {val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = create_n2v_configuration(\n",
    "    experiment_name=\"w2s_n2v_test\",\n",
    "    data_type=\"array\",\n",
    "    axes=\"SYX\",\n",
    "    patch_size=(64, 64),\n",
    "    batch_size=32, # 256, 32\n",
    "    num_epochs=100, # 1000, 15\n",
    "    n_channels=1\n",
    ")\n",
    "\n",
    "log.info(\"Initializing CAREamist...\")\n",
    "careamist = CAREamist(\n",
    "    source=config,\n",
    "    work_dir='models/noise2void_weights/'\n",
    ")\n",
    "\n",
    "log.info(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info(\"Training the model...\")\n",
    "careamist.train(train_source=train.reshape(-1, 512, 512), val_source=val.reshape(-1, 512, 512))     \n",
    "log.info(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info(\"Predicting on a noisy image...\")\n",
    "\n",
    "prediction = careamist.predict(\n",
    "    source=noisy_image.reshape(1, 512, 512),\n",
    "    batch_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics\n",
    "log.info(\"Computing metrics...\")\n",
    "metrics = compute_metrics(np.array(prediction[0]).squeeze(), ground_truth_image)\n",
    "\n",
    "# Print the computed metrics\n",
    "log.info(f\"PSNR: {metrics[0]}\")\n",
    "log.info(f\"SI-PSNR: {metrics[1]}\")\n",
    "log.info(f\"SSIM: {metrics[2]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
